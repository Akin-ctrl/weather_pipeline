{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d93a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import requests\n",
    "import psycopg2\n",
    "import schedule\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f76a6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nigerian cities found: 521\n",
      "['Zuru', 'Zungeru', 'Zaria', 'Zango', 'Zalanga', 'Zaki Biam', 'Zadawa', 'Yuli', 'Yola', 'Yenagoa', 'Yelwa', 'Yashikira', 'Yandev', 'Yanda Bayo', 'Yamrat', 'Yajiwa', 'Wuyo', 'Wusasa', 'Wurno', 'Wukari', 'Wudil', 'Wawa', 'Wauro Jabbe', 'Wasagu', 'Warri', 'Wamba', 'Walmayo', 'Wagini', 'Vom', 'Uyo']\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load credentials and settings from environment variables\n",
    "OPENWEATHER_API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\") # This will be 'db' from docker-compose\n",
    "\n",
    "# List of cities to monitor\n",
    "with open(\"city.list.json\", \"r\", encoding=\"utf-8\") as read:\n",
    "    cities = json.load(read)\n",
    "\n",
    "# Filter cities for Nigeria (country code = 'NG')\n",
    "nigeria_cities = [c for c in cities if c[\"country\"] == \"NG\"]\n",
    "\n",
    "# Extract just the city names into a list\n",
    "nigeria_city_names = [c[\"name\"] for c in nigeria_cities]\n",
    "\n",
    "# Print some details\n",
    "print(f\"Total Nigerian cities found: {len(nigeria_city_names)}\")\n",
    "print(nigeria_city_names[:30])  # print first 30 cities for preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556a4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather(city: str) -> dict | None:\n",
    "    \"\"\"Fetches weather data for a given city from the OpenWeatherMap API.\"\"\"\n",
    "    api_url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}\"\n",
    "    try:\n",
    "        response = requests.get(api_url, timeout=10)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx or 5xx)\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"API request failed for {city}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_weather_data(city: str, data: dict) -> dict | None:\n",
    "    \"\"\"Processes raw JSON data into a structured dictionary.\"\"\"\n",
    "    if not data:\n",
    "        return None\n",
    "    try:\n",
    "        processed = {\n",
    "            \"city_name\": city,\n",
    "            # Convert temperature from Kelvin to Celsius\n",
    "            \"temperature\": round(data['main']['temp'] - 273.15, 2),\n",
    "            \"humidity\": data['main']['humidity'],\n",
    "            \"pressure\": data['main']['pressure'],\n",
    "            \"wind_speed\": data['wind']['speed'],\n",
    "            \"weather_main\": data['weather'][0]['main'],\n",
    "            \"weather_desc\": data['weather'][0]['description'],\n",
    "            # Convert Unix timestamp to a timezone-aware datetime object\n",
    "            \"reading_timestamp\": datetime.fromtimestamp(data['dt'], tz=timezone.utc)\n",
    "        }\n",
    "        return processed\n",
    "    except (KeyError, IndexError) as e:\n",
    "        logging.error(f\"Error processing data for {city}. Missing key: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def weather_pipeline_job():\n",
    "    \"\"\"Main ETL process for all Nigerian cities.\"\"\"\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    logging.info(\"Starting weather data pipeline job...\")\n",
    "\n",
    "    # Ensure data folder exists\n",
    "    os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "    all_raw_data = []\n",
    "    all_processed_data = []\n",
    "\n",
    "    for city in nigeria_city_names:\n",
    "        logging.info(f\"Fetching weather data for {city}...\")\n",
    "\n",
    "        try:\n",
    "            raw_data = fetch_weather(city)\n",
    "\n",
    "            # Skip empty or failed responses\n",
    "            if not raw_data:\n",
    "                logging.warning(f\"No data returned for {city}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Normalize raw API data safely\n",
    "            pd_raw_data = pd.json_normalize(raw_data)\n",
    "            pd_raw_data[\"city\"] = city\n",
    "            all_raw_data.append(pd_raw_data)\n",
    "\n",
    "            # Processed data (assumes your function returns dict or list of dicts)\n",
    "            processed_data = process_weather_data(city, raw_data)\n",
    "            pd_processed_data = pd.DataFrame([processed_data])\n",
    "            pd_processed_data[\"city\"] = city\n",
    "            all_processed_data.append(pd_processed_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {city}: {e}\")\n",
    "\n",
    "    # Combine and save once after the loop\n",
    "    if all_raw_data:\n",
    "        df_raw = pd.concat(all_raw_data, ignore_index=True)\n",
    "        df_raw.to_csv(\"./data/raw.csv\", index=False)\n",
    "        logging.info(f\"Saved raw data for {len(df_raw)} cities.\")\n",
    "\n",
    "    if all_processed_data:\n",
    "        df_processed = pd.concat(all_processed_data, ignore_index=True)\n",
    "        df_processed.to_csv(\"./data/processed.csv\", index=False)\n",
    "        logging.info(f\"Saved processed data for {len(df_processed)} cities.\")\n",
    "\n",
    "    logging.info(\"Weather data pipeline job finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42108241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-17 12:23:28,348 - INFO - Starting weather data pipeline job...\n",
      "2025-10-17 12:26:26,931 - INFO - Weather data pipeline job finished.\n"
     ]
    }
   ],
   "source": [
    "weather_pipeline_job()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
